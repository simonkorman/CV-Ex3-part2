import logging 
import numpy as np
import random
import json
from PIL import Image
import math
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import torch

def collate_fn(batch):
    return tuple(zip(*batch))


def non_max_suppression(boxes, scores, threshold):
    """Performs non-maximum suppression and returns indices of kept boxes.
    boxes: [N, (y1, x1, y2, x2)]. Notice that (y2, x2) lays outside the box.
    scores: 1-D array of box scores.
    threshold: Float. IoU threshold to use for filtering.
    """
    assert boxes.shape[0] > 0
    if boxes.dtype.kind != "f":
        boxes = boxes.astype(np.float32)

    # Compute box areas
    y1 = boxes[:, 0]
    x1 = boxes[:, 1]
    y2 = boxes[:, 2]
    x2 = boxes[:, 3]
    area = (y2 - y1) * (x2 - x1)

    # Get indicies of boxes sorted by scores (highest first)
    ixs = scores.argsort()[::-1]

    pick = []
    while len(ixs) > 0:
        # Pick top box and add its index to the list
        i = ixs[0]
        pick.append(i)
        # Compute IoU of the picked box with the rest
        iou = compute_iou(boxes[i], boxes[ixs[1:]], area[i], area[ixs[1:]])
        # Identify boxes with IoU over the threshold. This
        # returns indices into ixs[1:], so add 1 to get
        # indices into ixs.
        remove_ixs = np.where(iou > threshold)[0] + 1
        # Remove indices of the picked and overlapped boxes.
        ixs = np.delete(ixs, remove_ixs)
        ixs = np.delete(ixs, 0)
    return np.array(pick, dtype=np.int32)

def compute_iou(box, boxes, box_area, boxes_area):
    """Calculates IoU of the given box with the array of the given boxes.
    box: 1D vector [y1, x1, y2, x2]
    boxes: [boxes_count, (y1, x1, y2, x2)]
    box_area: float. the area of 'box'
    boxes_area: array of length boxes_count.
    Note: the areas are passed in rather than calculated here for
    efficiency. Calculate once in the caller to avoid duplicate work.
    """
    # Calculate intersection areas
    y1 = np.maximum(box[0], boxes[:, 0])
    y2 = np.minimum(box[2], boxes[:, 2])
    x1 = np.maximum(box[1], boxes[:, 1])
    x2 = np.minimum(box[3], boxes[:, 3])
    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)
    union = box_area + boxes_area[:] - intersection[:]
    iou = intersection / union
    return iou


class ShapeDataset(torch.utils.data.Dataset):
  
  def __init__(self, num_examples, transforms=None):
    
    self.height = 128
    self.width = 128
    
    self.num_examples = num_examples
    self.transforms = transforms # IMPORTANT, DON'T MISS
    self.image_info = []
    self.logger = logging.getLogger(__name__)
    
    # Class Names: Note that the ids start from 1, not 0. This repo uses the index 0 for background
    # self.class_names = {"square": 1, "circle": 2, "triangle": 3}
    self.class_names = {"quad_rand": 1, "triangle_rand": 2}
    
    # Add images
    # Generate random specifications of images (i.e. color and
    # list of shapes sizes and locations). This is more compact than
    # actual images. Images are generated on the fly in load_image().
    for i in range(num_examples):
        bg_color, shapes = self.random_image(self.height, self.width)
        self.image_info.append({ "path":None,
                       "width": self.width, "height": self.height,
                       "bg_color": bg_color, "shapes": shapes
                       })
    
    # Fills in the self.coco varibale for evaluation.
    # self.get_gt()
    
    # Variables needed for coco mAP evaluation
    self.id_to_img_map = {}
    for i, _ in enumerate(self.image_info):
      self.id_to_img_map[i] = i

    self.contiguous_category_id_to_json_id = { 0:0 ,1:1, 2:2, 3:3 }

  def random_shape(self, height, width, bg_color):
    """Generates specifications of a random shape that lies within
    the given height and width boundaries.
    Returns a tuple of three values:
    * The shape name (square, circle, ...)
    * Shape color: a tuple of 3 values, RGB.
    * Shape dimensions: A tuple of values that define the shape size
                        and location. Differs per shape type.
    """
    # Shape
    # shape = random.choice(["square", "circle", "triangle"])
    shape = random.choice(["quad_rand", "triangle_rand"])
    # Color
    bg_c = np.array(bg_color)
    color = np.random.randint(0, 255, 3)
    while(np.mean(np.abs(bg_c-color)) < 100):
        color = np.random.randint(0, 255, 3)     
    color = tuple(color)
    # Center x, y
    buffer = 20
    y = random.randint(buffer, height - buffer - 1)
    x = random.randint(buffer, width - buffer - 1)
    # Size
    s = random.randint(buffer, height//4)
    return shape, color, (x, y, s)

  def random_image(self, height, width):
      """Creates random specifications of an image with multiple shapes.
      Returns the background color of the image and a list of shape
      specifications that can be used to draw the image.
      """
      # Pick random background color
      bg_color = np.array([random.randint(0, 255) for _ in range(3)])
      # Generate a few random shapes and record their
      # bounding boxes
      shapes = []
      boxes = []
      N = random.randint(1, 4)
      labels = {}
      for _ in range(N):
          shape, color, dims = self.random_shape(height, width, bg_color)
          shapes.append((shape, color, dims))
          x, y, s = dims
          boxes.append([y-s, x-s, y+s, x+s])

    #   Apply non-max suppression with 0.3 threshold to avoid
    #   shapes covering each other
      keep_ixs = non_max_suppression(np.array(boxes), np.arange(N), 0.2)
      shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]
      
      return bg_color, shapes
  
  
  def draw_shape(self, image, shape, dims, color):
      """Draws a shape from the given specs."""
      # Get the center x, y and the size s
      x, y, s = dims
      box = [ x-s, y-s, x+s, y+s]
      if shape == 'square':
          cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)
      elif shape == "circle":
          cv2.circle(image, (x, y), s, color, -1)
      elif shape == "triangle":
          points = np.array([[(x, y-s),
                              (x-s/math.sin(math.radians(60)), y+s),
                              (x+s/math.sin(math.radians(60)), y+s),
                              ]], dtype=np.int32)
          cv2.fillPoly(image, points, color)
      elif shape == "quad_rand":
          shifts = np.random.uniform(-1,1,4)*s/3          
          points = np.array([[(x-s, y+shifts[0]),
                              (x+shifts[1], y+s),
                              (x+s, y+shifts[2]),
                              (x-shifts[1], y-s),
                              ]], dtype=np.int32)
          cv2.fillPoly(image, points, color)
      elif shape == "triangle_rand":
          PI = np.pi
          base_theta = np.random.uniform(0,2*PI,1)
          shifts = np.random.uniform(-(PI)/16,PI/16,3)
          thetas = np.array([0,2*PI/3,2*PI*2/3]) + base_theta
          ct = np.cos(thetas)*s
          st = np.sin(thetas)*s
          points = np.array([[(x+ct[0], y+st[0]),
                              (x+ct[1], y+st[1]),
                              (x+ct[2], y+st[2]),
                              ]], dtype=np.int32)
          cv2.fillPoly(image, points, color)
          box = [min(x+ct), min(y+st), max(x+ct), max(y+st)]
      # print('====')
      # print('shape',shape,'x',x,'y',y,'s',s)
      # print('points',points)
      # print('box',box)
      return image, box


  def load_mask(self, image_id):
    """
    Generates instance masks for shapes of the given image ID.
    """
    info = self.image_info[image_id]
    shapes = info['shapes']
    count = len(shapes)
    info = self.image_info[image_id]
    bg_color = np.array(info['bg_color']).reshape([1, 1, 3])
    mask = np.ones([info['height'], info['width'], 3], dtype=np.uint8)
    mask = mask * bg_color.astype(np.uint8)
    
    boxes = []
    # print('++++++++++++++++ load_mask ++++++++++++++++++++++++')
    for shape, color, dims in info['shapes']:
        # mask[:, :, i:i+1], box = self.draw_shape(mask[:, :, i:i+1].copy(), shape, dims, 1)
        mask, box = self.draw_shape(mask, shape, dims, color)
        boxes.append(box)
        # print('draw box',box)
    # print('+++++++++++++++++++++++++++++++++++++++++++++++++++')

        
    # Handle occlusions
    occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)
    for i in range(count-2, -1, -1):
        mask[:, :, i] = mask[:, :, i] * occlusion
        occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))
    # Map class names to class IDs.
    class_ids = np.array([self.class_names[s[0]] for s in shapes])
    return mask.astype(np.uint8), class_ids.astype(np.int32), boxes
  
  def load_image(self, image_id):
    """Generate an image from the specs of the given image ID.
    Typically this function loads the image from a file, but
    in this case it generates the image on the fly from the
    specs in image_info.
    """
    info = self.image_info[image_id]
    bg_color = np.array(info['bg_color']).reshape([1, 1, 3])
    image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)
    image = image * bg_color.astype(np.uint8)
    for shape, color, dims in info['shapes']:
        image, _ = self.draw_shape(image, shape, dims, color)
    return image
      
  def __getitem__(self, idx):
    
    """Generate an image from the specs of the given image ID.
    Typically this function loads the image from a file, but
    in this case it generates the image on the fly from the
    specs in image_info.
    """
    # print('----------------------------------------------------------------------------------- item', idx, '----------')
    image = Image.fromarray(self.load_image(idx))
    mask, labels, boxes = self.load_mask(idx)
    
    # # create a BoxList from the boxes
    # boxlist = BoxList(boxes, image.size, mode="xyxy")

    # # add the labels to the boxlist
    # boxlist.add_field("labels", torch.tensor(labels))

    # Add masks to the boxlist
    # masks = np.transpose(masks, (2,0,1))
    # masks = SegmentationMask(torch.tensor(masks), image.size, "mask")
    # boxlist.add_field("masks", masks)
    
    # Important line! don't forget to add this
    if self.transforms:
        image, boxlist = self.transforms(image, boxlist)

    # return the image, the boxlist and the idx in your dataset
    target = {}
    target['bounding_box'] = torch.tensor(boxes)
    target['labels'] = torch.tensor(labels)
    
    return torch.tensor(np.asarray(mask)).permute(2,0,1), target
  
  
  def __len__(self):
      return self.num_examples
    

  def get_img_info(self, idx):
      # get img_height and img_width. This is used if
      # we want to split the batches according to the aspect ratio
      # of the image, as it can be more efficient than loading the
      # image from disk

      return {"height": self.height, "width": self.width}
    
  def get_gt(self):
      # Prepares dataset for coco eval
      
      images = []
      annotations = []
      results = []
      
      # Define categories
      categories = [ {"id": 1, "name": "square"}, {"id": 2, "name": "circle"}, {"id": 3, "name": "triangle"}]


      i = 1
      ann_id = 0

      for img_id, d in enumerate(self.image_info):

        images.append( {"id": img_id, 'height': self.height, 'width': self.width } )

        for (shape, color, dims) in d['shapes']:
          
          if shape == "square":
            category_id = 1
          elif shape == "circle":
            category_id = 2
          elif shape == "triangle":
            category_id = 3
          if shape == "square":
            category_id = 1
          elif shape == "triangle_rand":
            category_id = 2
          elif shape == "quad_rand":
            category_id = 3         
            
          x, y, s = dims
          bbox = [ x - s, y - s, x+s, y +s ] 
          area = (bbox[0] - bbox[2]) * (bbox[1] - bbox[3])
          
          # Format for COCO
          annotations.append( {
              "id": int(ann_id),
              "category_id": category_id,
              "image_id": int(img_id),
              "area" : float(area),
              "bbox": [ float(bbox[0]), float(bbox[1]), float(bbox[2]) - float(bbox[0]) + 1, float(bbox[3]) - float(bbox[1]) + 1 ], # note that the bboxes are in x, y , width, height format
              "iscrowd" : 0
          } )

          ann_id += 1

      # Save ground truth file
      
      with open("tmp_gt.json", "w") as f:
        json.dump({"images": images, "annotations": annotations, "categories": categories }, f)

      # Load gt for coco eval
      self.coco = COCO("tmp_gt.json")

def draw_box(ax, box):
    color = 'black'
    ex1 = box[0]
    ey1 = box[1]
    ex2 = box[2]
    ey2 = box[3]
    rect = patches.Rectangle((ex1,ey1),abs(ex1 - ex2),abs(ey1 - ey2),linewidth=2, edgecolor=color, fill=False)
    ax.add_patch(rect)


def get_shapes_loader(batch_sz, train_samples=100, val_samples=48, test_samples=84):
  train_dt = ShapeDataset(train_samples)
  val_dt = ShapeDataset(val_samples)
  test_dt = ShapeDataset(test_samples)
  train_loader = torch.utils.data.DataLoader(train_dt, batch_size=batch_sz, shuffle=True, num_workers=0, collate_fn=collate_fn)
  val_loader = torch.utils.data.DataLoader(val_dt, batch_size=batch_sz, shuffle=True, num_workers=0, collate_fn=collate_fn)
  test_loader = torch.utils.data.DataLoader(test_dt, batch_size=batch_sz, shuffle=True, num_workers=0, collate_fn=collate_fn)

  print('-----------------------------')
  print('-------   V 21   ------------')
  print('-----------------------------')

  return train_loader, val_loader, test_loader
